---
title: "Уровень каких белков различается в мышиной модели синдрома Дауна "
date: "29 02 2020"
output: html_document
---


Загрузка необходимых пакетов

```{r setup, echo=TRUE,message=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(readxl)
library(ggplot2)
library(dunn.test)
library(multcomp)
library(pca3d)
library(vegan)
library(car)
```

Для загрузки датасета воспользуемся функцией read_excel из пакета **readxl**
```{r,echo=TRUE}
nucl <- read_excel('C:/Users/Alexandra Dolgikh/Downloads/Data_Cortex_Nuclear.xls')
```

Как мы видим, в таблице у нас содержится 1080 измерений значений различных белков и некоторая классификация для групп, на которые можно подразделить данные этих измерений. Как становится ясно из описания датасета у нас существует 8 классов мышей, в которых комбинируются различные условия. Во-первых, это наличие или отсутствие у мышей трисомии в локусах, затрагивающих гены, ассоциированные с синдромом Дауна. В этом случае мыши делятся на Control и мутантную линию Ts65Dn. Также существовало деление мышей на группы в зависимости от того, когда на них было оказано шоковое воздействие посредством электрического тока. Группа context-shock(CS) сначала была помещена на 3 минуты в новое помещение, а уже потом было осуществлено воздействие электрическим током, а для группы shock-context все было сделано ровно наоброт. Также мыши были поделены на группы, которым вводили инъекции либо мемантина, либо соляного раствора. Таким образом, всего в эксперименте был исследовано 8 классов. 

Всего в эксперименте участвовали 72 мыши, 38 из них обозначены как контрольные, а 34 содержат трисомию. Для каждой мыши интересующие белки были измерены в 15-кратной повторности. 

Оценим количество наблюдений в разных классах.
```{r}
table(nucl$class)
```
Видим, что количество измерений в разных классах несбалансированно, потому что для каждого биологического образца(соответсвующего данным с одной мыши)было проведено 15 технических измерений, а здесь цифры не равны. 

Для того, чтобы определить количество наблюдений, для которых данные являются является полными по всем белкам, воспользуемся следующей функцией

```{r}
sum(complete.cases(nucl))
```
Как мы видим лишь половина наблюдений являются полными.

## Различия в уровне продукции BDNF_N в зависимости от класса 


Теперь, оценим уровень продукции белка **BDNF_N** в зависимости от класса

Для начала проверим, сколько в векторе соответствующем данному белку пропущенных значений

```{r}
sum(is.na(nucl$BDNF_N))
```

Видим, что пропущенных значений всего три. С учетом 1080 значений 3 это немного, поэтому в данном случае заменим NA на среднее и сразу проверим, что пропущенных значений теперь нет

```{r}
nucl$BDNF_N[is.na(nucl$BDNF_N)]<-mean(nucl$BDNF_N,na.rm=T)
sum(is.na(nucl$BDNF_N))
```

Оценим, как распределены данные по классам

```{r}
BDNF <- nucl[,c("BDNF_N","class")]
table(BDNF$class)
```

Как мы видим, количество наблюдений по продукции данного белка в разных классах также не равно (что по сути понятно и из того, что у нас в целом разное количество мышей в разных классах)

Соответственно, дисперсионный анализ будет здесь не так устойчив к выбросам. Но посмотрим на основные условия применимости дисперсионного анализа. Для этого для начала построим линейную модель.

```{r pressure, echo=FALSE}
library(car)
mod_nucl <- lm(BDNF_N ~ class, data = nucl)
```

Теперь с использованием вывода функции fortify и пакета ggplot построим график расстояний кука для оценки наличия влиятельных наблюдений
```{r , echo=FALSE}
mod_diag <- fortify(mod_nucl)
ggplot(mod_diag, aes(x = 1:nrow(mod_diag), y = .cooksd)) + geom_bar(stat = "identity") +geom_hline(yintercept = 2, color = "green2")+ ggtitle("График расстояний Кука")

```

Влиятельных наблюдений мы не видим. Посмотрим также, есть ли разброс в дисперсии остатков.

```{r}
ggplot(mod_diag, aes(x = class, y = .stdresid)) + geom_boxplot() + ggtitle("График остатков от предсказанных значений")

```

Как мы видим, разброс в дисперсии все же есть и поскольку у нас группы не сбалансированы по количеству наблюдений, мы все же воспользуемся непараметрическим аналогом ANOVA - тестом Краскелла-Уоллиса.

```{r}
kruskal.test(BDNF_N ~ class, data = nucl)
```

Видим, что значение p-value значимо меньше 0.05, а значит между классами существует разница в экспрессии гена BDNF_N

В качестве пост-хок теста используем Dunn test
```{r}
dunn.test(nucl$BDNF_N,nucl$class,method = 'bonferroni')
```


Визуализируем полученные данные 

```{r}
ggplot(data=nucl,aes(x=class,y=BDNF_N,color=class))+geom_boxplot()
```

В совокупности из данных пост-хок теста и графика можем увидеть несколько различий. Например, между контрольными группами context-shock после обработки солью и мемантином разницы нет, тогда как сравнение обеих вариантов контрольных групп context-shock с соответствующими группами shock-context уже показывает значимую разницу в продукции белка.

Теперь построим линейную модель, чтобы...

## Предсказать уровень продукции белка ERBB4_N по данным о других белках

```{r}

full_lm <- lm(ERBB4_N~.,nucl[,-c(1,79,80,81,82)])
summary(full_lm)
```

Как мы видим, в коэффициентах модели присутствует строка NA, а значит мы не можем построить модель не исключив данный коэффициент, так как по видимому он линейно коррелирует с каким-то другим коэффициентом

```{r}
full_2 <- update(full_lm, .~. - pS6_N)
full_lm_for <- data.frame(fortify(full_2))
gg_resid <- ggplot(data = full_lm_for, aes(x = .fitted, y = .stdresid)) + 
  geom_point() + 
  geom_hline(yintercept = 0) +
  geom_smooth(method = "lm") +
  geom_hline(yintercept = 2, color = "red") +
  geom_hline(yintercept = -2, color = "red") +
  ggtitle("График остатков для полной модели")
gg_resid
```

Гетероскедастичности и нелинейности остатков не видим, но тем не менее есть наблюдения, выходящие из зоны +- 2 стандартных отклонения.

Построим график расстояний кука для оценки наличия влиятельных наблюдений

```{r}
ggplot(, aes(x = 1:nrow(full_lm_for), y = full_lm_for$.cooksd)) + 
  geom_bar(stat = "identity") + 
  geom_hline(yintercept = 2, color = "green2") + ggtitle("График расстояний Кука для полной модели")
```

Ни одно значение не превышает условного порога в 2 единицы, а значит влиятельных наблюдений нет

А теперь посмотрим как в датасете обстоит дело с мультиколлинеарностью
```{r}
vif(full_2)
```

И видим для всех предикторов большие значения VIF, иногда значительно превышающие порог 2.
Видимо, идея в данном случае строить полную модель плоха, так как уровни продукции белков достаточно часто коррелируют, что может вносить большие затруднения в построение качественной модели. Наверное, имеет смысл в данном случае исходя из каких-то предположений выбирать небольшие группы белков, проверять эти группы на наличие мультиколлинеарности и уже тогда строить линейные модели.



## Анализ главных компонент


Для проведения анализа главных компонент воспользуемся пакетом **vegan**. Так же предварительно уберем из датасета неполные наблюдения.

```{r}
nucl_complete <- nucl[complete.cases(nucl),]
nucl_pca <- rda(nucl_complete[,-c(1,79,80,81,82)], scale = TRUE)
```

В данном случае у нас получается 76 компонент.

Построим график нагрузок с использованием функции **biplot**. 

```{r}
biplot(nucl_pca, scaling = "species", display = "species")
```
В данном случае достаточно сложно выделить какие признаки коррелируют с друг другом, так как углы между векторами примерно одинаковы и никаких хорошо очерченных групп не выделяется.

Теперь построим график ординации, чтобы оценить сходство между наблюдениями в различных группах. Для визуализации воспользуемся пакетом **ggplot2**
```{r}
df_scores <- data.frame(nucl_complete,
                        scores(nucl_pca, display = "sites", choices = c(1, 2, 3), scaling = "sites"))


p_scores <- ggplot(df_scores, aes(x = PC1, y = PC2)) +  geom_point(aes( color = class), alpha = 0.5) +coord_equal(xlim = c(-1.2, 1.2), ylim = c(-1.2, 1.2)) + ggtitle(label = "Classes")+theme_bw()
p_scores
```

Как мы видим, четких кластеров для восьми классов выявить также не удается. Попробуем сделать разделения на 2 группы по разным факторам. 

```{r}
p_scores <- ggplot(df_scores, aes(x = PC1, y = PC2)) +  geom_point(aes( color = Treatment), alpha = 0.5) +coord_equal(xlim = c(-1.2, 1.2), ylim = c(-1.2, 1.2)) + ggtitle(label = "Treatment")+theme_bw()
p_scores
````

```{r}
p_scores <- ggplot(df_scores, aes(x = PC1, y = PC2)) +  geom_point(aes( color = Genotype), alpha = 0.5) +coord_equal(xlim = c(-1.2, 1.2), ylim = c(-1.2, 1.2)) + ggtitle(label = "Genotype")+theme_bw()
p_scores
```

```{r}
p_scores <- ggplot(df_scores, aes(x = PC1, y = PC2)) +  geom_point(aes( color = Behavior), alpha = 0.5) +coord_equal(xlim = c(-1.2, 1.2), ylim = c(-1.2, 1.2)) + ggtitle(label = "Behavior")+theme_bw()
p_scores
```

Как мы видим, во всех группах при делении на 2 класса данные также плохо расходятся, но в поведении видим хорошую кластеризацию. То есть именно этот фактор особенно интересен для дальнейшего изучения один, а не в совокупности.

Посмотрим, какой вклад вносит каждая из компонент. Для этого визализируем результаты summary  PCA анализа с помощью barplot

```{r}
pca_summary <- summary(nucl_pca)
pca_result <- as.data.frame(pca_summary$cont)
plot_data <- as.data.frame(t(pca_result[c("Proportion Explained"),]))
plot_data$component <- rownames(plot_data)

ggplot(plot_data, aes( component, `Proportion Explained`)) + geom_bar(stat = "identity") + theme_bw()+theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

Видим, что действительно самый большой процент объясняет компонента PC1, а дальше уже идет вклад PC2 и т.д. Тем не менее вклад PC3 от PC4 уже сильно не различается.
